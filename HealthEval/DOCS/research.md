# ðŸ“‘ Research Foundations for HealthEval

HealthEvalâ€™s evaluation framework is grounded in peer-reviewed evidence on medical AI, patientâ€“clinician communication, and trustworthy system design. Each metric is explicitly traceable to published research.

---

### CONSORT-AI & SPIRIT-AI (Nature Medicine, 2020) â€” reporting standards for AI in trials
Spell out intended use, input requirements, humanâ€“AI interaction, error analysis, and deployment context so claims are interpretable and reproducible.  
âž¡ Maps to HealthEvalâ€™s **Evidence & Transparency** bar.  
ðŸ”— [Nature Medicine](https://www.nature.com/articles/s41591-020-1034-x?utm_source=chatgpt.com)

---

### Ayers et al., JAMA Internal Medicine (2023) â€” physicians vs. chatbot replies
Blinded clinicians preferred chatbot answers 4:1 for quality and empathy on real patient questions, partly due to longer, more thorough replies.  
âž¡ Motivates separating **Clinical Safety** (correctness/escalation) from **Empathy & Relationship Quality** (tone, validation).  
ðŸ”— [JAMA Network](https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2804309?utm_source=chatgpt.com)

---

### Kelley et al., PLoS ONE (2014) â€” patientâ€“clinician relationship â†’ outcomes
Meta-analysis of randomized controlled trials: the relationship itself improves clinical and subjective outcomes.  
âž¡ Justifies scoring **tone, validation, and partnership** alongside factual safety.  
ðŸ”— [PLOS ONE](https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0094207&utm_source=chatgpt.com)

---

### Batbaatar et al., Systematic Review (2017) â€” determinants of patient satisfaction
Across settings, **interpersonal care, communication, and technical skill** dominate satisfaction. Demographic effects are inconsistent.  
âž¡ Informs **Clarity & Comprehension** (plain language, structure) and **Empathy** (interpersonal care).  
ðŸ”— [PubMed](https://pubmed.ncbi.nlm.nih.gov/27004489/?utm_source=chatgpt.com)

---

### Derksen et al., Br J Gen Pract (2012) â€” empathy works
Empathy correlates with higher satisfaction, adherence, lower anxiety, and better diagnostics/outcomes.  
âž¡ Supports an explicit **Empathy & Respect** subscore (validation, nonjudgmental phrasing).  
ðŸ”— [PubMed Central](https://pmc.ncbi.nlm.nih.gov/articles/PMC3529296/?utm_source=chatgpt.com)

---

### Robertson et al., PLOS Digital Health (2023) â€” diverse patientsâ€™ attitudes toward AI
Patients value AIâ€™s accuracy but hesitate to trust automation; uptake improves with careful framing, physician-led use, and transparency.  
âž¡ Backs **Trust, Explainability & User Agency** and **Clinical Safety & Escalation** metrics.  
ðŸ”— [PLOS Digital Health](https://journals.plos.org/digitalhealth/article?id=10.1371%2Fjournal.pdig.0000237&utm_source=chatgpt.com)

---

### Shevtsova et al., JMIR Human Factors (2024) â€” trust & acceptance of medical AI
Trust is shaped by transparency, reliability, usability, and user education. Clear limitations, uncertainty, and reasoning statements are essential.  
âž¡ Anchors **Evidence & Transparency** and **Trust, Explainability & User Agency**.  
ðŸ”— [JMIR Human Factors](https://humanfactors.jmir.org/2024/1/e47031?utm_source=chatgpt.com)

---

### Singh et al., npj Digital Medicine (2023) â€” chatbots for health behaviors
Meta-analysis finds chatbot interventions can improve physical activity, diet, and sleep, but quality/design vary. **Plan specificity** and **adherence support** (reminders, barrier-planning) are critical.  
âž¡ Shapes **Plan Quality & Behavior Support**.  
ðŸ”— [npj Digital Medicine](https://www.nature.com/articles/s41746-023-00856-1?utm_source=chatgpt.com)

---

## ðŸ“Œ Metric â†” Research Mapping
- **Evidence & Transparency** â†’ CONSORT-AI, Shevtsova et al.  
- **Clinical Safety & Escalation** â†’ CONSORT-AI, Ayers et al., Robertson et al.  
- **Empathy & Relationship Quality** â†’ Ayers et al., Kelley et al., Derksen et al., Batbaatar et al.  
- **Clarity & Comprehension** â†’ Batbaatar et al.  
- **Plan Quality & Behavior Support** â†’ Singh et al.  
- **Trust, Explainability & User Agency** â†’ Robertson et al., Shevtsova et al.  

