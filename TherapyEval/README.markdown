# Therapy Model Evaluator

The **Therapy Model Evaluator** (powered by the Care-Lock variant) is an AI-powered tool designed to assess how well large language models (LLMs) perform in therapeutic conversations. It evaluates models on 10 core psychological and conversational metrics, simulating the quality of a therapist's empathy, ethical safety, and conversational coherence. Ideal for developers, researchers, or anyone testing AI for mental health support or emotionally sensitive applications.

## Main Aim
The tool evaluates both open-source and paid LLMs on their ability to handle therapy-like interactions. It measures qualities like empathy, boundary awareness, and ethical safety, ensuring models respond like a caring counselor while avoiding harm or overreach.

## How It Works
The evaluation follows a structured process:
1. **Parse Conversation**: Breaks down input transcripts into structured JSON (e.g., `{"idx":1, "speaker":"HUMAN", "text":"I'm feeling overwhelmed."}`).
2. **Identify Key Moments**: Detects up to 5 pivotal emotional or ethical moments with justifications.
3. **Score Metrics**: Evaluates 10 skills (e.g., Empathy, Ethical Safety, Clarity) on a 0-1 scale, based on 5 sub-checks per metric (raw score 0-5, converted to tiers: 5/5=1.0, 4/5=0.8, etc.).
4. **Self-Audit**: Ensures logical consistency across scores.
5. **Output**: Provides detailed tables, JSON, and summaries.

### Example Output
| Model              | Empathy | Emotional Relevance | Tone | Boundary Awareness | Supportiveness | Ethical Safety | Clarity | Consistency | Self-Awareness | Adaptability | Total Score |
|--------------------|---------|----------------------|------|--------------------|----------------|----------------|---------|-------------|---------------|-------------|-------------|
| GPT-4o-mini       | 0.8    | 1.0                 | 1.0 | 0.4               | 0.8           | 1.0           | 0.8    | 0.6        | 0.6          | 0.1        | 0.71       |
| Claude-3.5-Sonnet | 0.8    | 0.8                 | 1.0 | 0.4               | 0.8           | 1.0           | 1.0    | 0.6        | 0.6          | 0.1        | 0.71       |
| DeepSeekChat      | 0.8    | 1.0                 | 0.8 | 0.8               | 0.8           | 1.0           | 0.8    | 0.6        | 0.6          | 0.1        | 0.73       |

**Pros Example**:
- "Validates user feelings consistently with warm tone."
- "Provides practical grounding strategies."

**Cons Example**:
- "Missed referral to professional help." â†’ *Suggestion*: "Consider trauma-informed therapy referral."

**Output Formats**:
- **Table View**: Metric scores (0-1) per model with total score.
- **JSON**: Structured output with conversation turns, key moments, metrics, and summaries.
- **Artifacts**: Downloadable JSON file (`carencolavali_YYYYMMDD_HHMMSS.json`).

## Use Cases
- Comparing LLMs for mental health support tasks.
- Testing ethical and emotionally sensitive AI responses.
- Generating structured feedback for model improvement.

## Try It Without Installation
To avoid setup hassle, use the hosted version on Hugging Face:  
[BrainDrive/Therapy-Model-Evaluator](https://huggingface.co/spaces/BrainDrive/Therapy-Model-Evaluator)

## Installation
To run locally:

1. Clone the repository:
   ```bash
   git clone https://github.com/BrainDriveAI/ModelMatch.git
   ```

2. Navigate to the `Therapyeval` directory:
   ```bash
   cd ModelMatch
   cd Therapyeval
   ```

3. Install dependencies (requires Python 3.8+ and pip):
   ```bash
   pip install -r requirements.txt
   ```

4. Set API keys as environment variables:
   - **macOS/Linux**:
     ```bash
     export OPENAI_API_KEY=your_openai_key_here
     export ANTHROPIC_API_KEY=your_anthropic_key_here
     export DEEPSEEK_API_KEY=your_deepseek_key_here
     ```
     Optionally, add to `~/.bash_profile` or `~/.zshrc` for persistence, then:
     ```bash
     source ~/.bash_profile
     ```

   - **Windows (Command Prompt)**:
     ```cmd
     set OPENAI_API_KEY=your_openai_key_here
     set ANTHROPIC_API_KEY=your_anthropic_key_here
     set DEEPSEEK_API_KEY=your_deepseek_key_here
     ```
     Or use Git Bash with `export` syntax.

5. Run the application:
   - **macOS/Linux**:
     ```bash
     python3 app.py
     ```
   - **Windows**:
     ```cmd
     python app.py
     ```

6. Access the interface at: [http://127.0.0.1:7860/](http://127.0.0.1:7860/)

## Features
- **Input**: Paste plain text or JSON conversation transcripts.
- **Evaluator Models**: Choose up to 3 (e.g., GPT-4o-mini, Claude-3.5-Sonnet, DeepSeekChat).
- **Temperature Slider**: Adjust creativity (0-1 range).
- **Metrics**: Weighted scores for Empathy (0.2), Emotional Relevance (0.15), Tone (0.1), Boundary Awareness (0.1), Supportiveness (0.1), Ethical Safety (0.1), Clarity (0.1), Consistency (0.1), Self-Awareness (0.05), Adaptability (0.05).
- **Output**: Detailed tables, JSON, and downloadable artifacts.

## Disclaimer
This tool evaluates AI performance in therapeutic scenarios but is not a replacement for professional human therapy. Use responsibly.

## Conclusion
The Therapy Model Evaluator empowers users to select reliable LLMs for mental health and emotional support applications through rigorous, metric-based assessments.